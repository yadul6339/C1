{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Day my_02_Estimation (1).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zerryberry/C1/blob/master/Stats_Day_my_02_Estimation_(1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6oqSQYwjz42c"
      },
      "source": [
        "---------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4TGH8Ivz42d"
      },
      "source": [
        "**Problem**) From the given Population & Sample data calculate the followings.\n",
        "\n",
        "#### a)calculate an estimate of mean with 90% confidence level."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqphHAX7z42e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7664af0d-f56e-4efc-ce4e-d6c13746e15f"
      },
      "source": [
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "np.random.seed(11)\n",
        "population_horsepower1 = stats.poisson.rvs(loc=1800, mu=25, size=15000)\n",
        "population_horsepower2 = stats.poisson.rvs(loc=1800, mu=5, size=10000)\n",
        "population_hp = np.concatenate((population_horsepower1, population_horsepower2))\n",
        "\n",
        "print(population_hp) # population data"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1820 1824 1824 ... 1808 1806 1804]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FyG3U24Jz42i"
      },
      "source": [
        "np.random.seed(11)\n",
        "\n",
        "sample_size = 100\n",
        "sample = np.random.choice(a= population_hp, size = sample_size)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OP47RMxXz42o"
      },
      "source": [
        "**Solution :**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HM--kuxcz42p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08f91655-68f3-41dd-830b-42f41476485d"
      },
      "source": [
        "xbar= np.mean(sample)\r\n",
        "xbar"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1816.17"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KIgfK1G9rM5o"
      },
      "source": [
        "mu= np.mean(population_hp)\r\n",
        "sigma= np.std(population_hp)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33Ocywk8rM8n",
        "outputId": "9c1f2f59-6a95-44ad-a0e1-5c5983ecfe03"
      },
      "source": [
        "stats.norm.interval(0.9,loc=mu, scale= sigma)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1799.5231002225696, 1834.5024997774303)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SiHFvkIPsR6K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76e6fde1-3517-421a-83e6-f72a9d6ddc5f"
      },
      "source": [
        "# so we are 90% confident that the mean is between 1799.5231002225696 and  1834.5024997774303\r\n",
        "print(mu)\r\n",
        "print(xbar)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1817.0128\n",
            "1816.17\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Riqm39ICz42t"
      },
      "source": [
        "----------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SjHSHwXdz42w"
      },
      "source": [
        "**Problem)**. Hindustan Pencils Pvt. Ltd. is an Indian manufacturer of pencils, writing materials and other stationery items, established in 1958 in Mumbai. Pencils manufactured by Nataraj company is expected to have a mean length of 172 mm and the standard deviation of the length is 0.02 mm.\n",
        "To ensure the quality, a sample is selected at periodic intervals to determine whether the length is still 172 mm meet the quality standards set by the company.You select a random sample of 100 pencils follows a normal distribution and the mean is 170 mm.**\n",
        "\n",
        "* a)Construct a 99% confidence interval for the pencil length."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oz6gtOB9z420"
      },
      "source": [
        "**Solution :**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gvP67fhpz424"
      },
      "source": [
        "It is known that \n",
        "* $\\overline{X}$ = 172 mm\n",
        "* $\\sigma$       = 0.02 mm\n",
        "* n              = 100\n",
        "We need to compute $\\overline{X} \\quad \\pm 2.5783 \\frac {\\sigma} {\\sqrt{n}}$ "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Izc2H9IFz426",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ba7e05a-3105-4cf4-d16b-f579f67c6db0"
      },
      "source": [
        "stats.norm.interval(0.99,loc=172, scale= 0.02)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(171.948483413929, 172.051516586071)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRqsr2oyfoS5"
      },
      "source": [
        "# we got an xbar as - 170"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vggq9zNns1V5",
        "outputId": "c0628080-6b73-4c41-d33a-9c2880e6e8e2"
      },
      "source": [
        "# so for being 90% confident that the sample mean is following the decided mean, our sample mean should be between 171.948483413929 and  172.051516586071"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "170.0051566"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3AAoAC2tEu2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKEk-YeqgE9G"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}